{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1957978",
   "metadata": {},
   "source": [
    "# Kotlin Clothing Webshop recommender algorithms and inspections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b5b4bc",
   "metadata": {},
   "source": [
    "## 1. Simple collaborative filtering retrieval algorithm based on matrix factorization and two tower model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae637e3",
   "metadata": {},
   "source": [
    "### 1. Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49425095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "from typing import Dict, Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0931c0e4",
   "metadata": {},
   "source": [
    "### 2. Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ece579f",
   "metadata": {},
   "source": [
    "#### 1. Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23051254",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_articles = \"C:\\\\Sajat\\\\Egyetem\\\\MSc\\\\Onallo\\\\HM_dataset\\\\articles.csv\"\n",
    "path_to_transactions = \"C:\\\\Sajat\\\\Egyetem\\\\MSc\\\\Onallo\\\\HM_dataset\\\\transactions_train.csv\"\n",
    "\n",
    "article_df = pd.read_csv(path_to_articles)\n",
    "transactions_df = pd.read_csv(path_to_transactions)\n",
    "\n",
    "article_df[\"article_id\"] = article_df[\"article_id\"].astype(str)\n",
    "transactions_df[\"article_id\"] = transactions_df[\"article_id\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67acca9",
   "metadata": {},
   "source": [
    "#### 2. Reduce the size of the dataset to boost testing speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93392482",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_date = transactions_df[\"t_dat\"]\n",
    "\n",
    "first_transaction_date = \"2019-09-20\"\n",
    "last_transaction_date = \"2020-09-20\"\n",
    "\n",
    "# Reduce the size of dataframe to make tests faster\n",
    "train_df_first_transaction_date = \"2020-09-17\" #\"2020-09-03\"\n",
    "train_df_and_test_df_separator_date = \"2020-09-19\" #\"2020-09-17\"\n",
    "test_df_last_transaction_date = \"2020-09-20\" #\"2020-09-20\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0414fddf",
   "metadata": {},
   "source": [
    "#### 3. Split the dataset into training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d7722f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of articles: 2638550\n",
      "Count of transactions: 158941620\n",
      "Count of training transactions: 380400\n",
      "Count of test transactions: 157445\n"
     ]
    }
   ],
   "source": [
    "filtered_transactions_df = transactions_df[(transactions_date > train_df_first_transaction_date) & (transactions_date <= test_df_last_transaction_date)]\n",
    "train_transactions_df = transactions_df[(transactions_date > train_df_first_transaction_date) & (transactions_date <= train_df_and_test_df_separator_date)]\n",
    "test_transactions_df = transactions_df[(transactions_date > train_df_and_test_df_separator_date) & (transactions_date <= test_df_last_transaction_date)]\n",
    "\n",
    "print(\"Count of articles:\", article_df.size)\n",
    "print(\"Count of transactions:\", transactions_df.size)\n",
    "print(\"Count of training transactions:\", train_df.size)\n",
    "print(\"Count of test transactions:\", test_df.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24295f8c",
   "metadata": {},
   "source": [
    "#### 3. Project only relevant item and query attributes and map pandas dataframe to tensorflow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05022ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_transaction(transactions):\n",
    "    return [transactions[\"customer_id\"], transactions[\"article_id\"]]\n",
    "\n",
    "\n",
    "articles = tf.data.Dataset.from_tensor_slices(\n",
    "    article_df[[\"article_id\"]].to_dict(orient=\"list\")\n",
    ").map(lambda x: x[\"article_id\"])\n",
    "transactions = tf.data.Dataset.from_tensor_slices(\n",
    "    filtered_transactions_df[[\"customer_id\", \"article_id\"]].to_dict(orient=\"list\")\n",
    ").map(project_transaction)\n",
    "customer_ids = tf.data.Dataset.from_tensor_slices(\n",
    "    filtered_transactions_df[[\"customer_id\"]].to_dict(orient=\"list\")\n",
    ").map(lambda x: x[\"customer_id\"])\n",
    "training_transactions_slices = tf.data.Dataset.from_tensor_slices(\n",
    "    train_transactions_df[[\"customer_id\", \"article_id\"]].to_dict(orient=\"list\")\n",
    ")\n",
    "training_transactions = training_transactions_slices.map(project_transaction)\n",
    "test_transactions_slices = tf.data.Dataset.from_tensor_slices(\n",
    "    test_transactions_df[[\"customer_id\", \"article_id\"]].to_dict(orient=\"list\")\n",
    ")\n",
    "test_transactions = test_transactions_slices.map(project_transaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd2dfe1",
   "metadata": {},
   "source": [
    "### 3. Implement the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72904622",
   "metadata": {},
   "source": [
    "#### 1. Define common embedding dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e10b7930",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e080b85",
   "metadata": {},
   "source": [
    "#### 2. Create StringLookup layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90af8c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_ids_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n",
    "customer_ids_vocabulary.adapt(customer_ids)\n",
    "article_ids_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n",
    "article_ids_vocabulary.adapt(articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad215cb7",
   "metadata": {},
   "source": [
    "#### 3. Implement the query tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d2d181c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n"
     ]
    }
   ],
   "source": [
    "customer_tower_model = tf.keras.Sequential([\n",
    "    customer_ids_vocabulary,\n",
    "    tf.keras.layers.Embedding(customer_ids_vocabulary.vocab_size(), embedding_dimension),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e42172a",
   "metadata": {},
   "source": [
    "#### 4. Implement the candidate tower model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6412a9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n"
     ]
    }
   ],
   "source": [
    "article_tower_model = tf.keras.Sequential([\n",
    "    article_ids_vocabulary,\n",
    "    tf.keras.layers.Embedding(article_ids_vocabulary.vocab_size(), embedding_dimension),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3225dca1",
   "metadata": {},
   "source": [
    "#### 5. Define task (metrics and loss) for two tower model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26656f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = tfrs.tasks.Retrieval(\n",
    "    metrics=tfrs.metrics.FactorizedTopK(\n",
    "        candidates=articles.batch(64).map(article_tower_model)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c68892e",
   "metadata": {},
   "source": [
    "#### 6. Implement the two tower model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9997217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoTowerModel(tfrs.Model):\n",
    "    \n",
    "    def __init__(self, query_tower_model, candidate_tower_model):\n",
    "        super().__init__()\n",
    "        self.candidate_tower_model: tf.keras.Model = candidate_tower_model\n",
    "        self.query_tower_model: tf.keras.Model = query_tower_model\n",
    "        self.task: tf.keras.layers.Layer = task\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        customer_embeddings = self.query_tower_model(features[\"customer_id\"])\n",
    "        positive_article_embeddings = self.candidate_tower_model(features[\"article_id\"])\n",
    "\n",
    "        return self.task(customer_embeddings, positive_article_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fc92d2",
   "metadata": {},
   "source": [
    "### 4. Fitting and evaluating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c626f53",
   "metadata": {},
   "source": [
    "#### 1. Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47ae9cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "75/75 [==============================] - 79s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0384 - factorized_top_k/top_5_categorical_accuracy: 0.3283 - factorized_top_k/top_10_categorical_accuracy: 0.3825 - factorized_top_k/top_50_categorical_accuracy: 0.5266 - factorized_top_k/top_100_categorical_accuracy: 0.6011 - loss: 5444.2019 - regularization_loss: 0.0000e+00 - total_loss: 5444.2019\n",
      "Epoch 2/3\n",
      "75/75 [==============================] - 95s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0852 - factorized_top_k/top_5_categorical_accuracy: 0.4127 - factorized_top_k/top_10_categorical_accuracy: 0.4762 - factorized_top_k/top_50_categorical_accuracy: 0.6111 - factorized_top_k/top_100_categorical_accuracy: 0.6784 - loss: 4635.8357 - regularization_loss: 0.0000e+00 - total_loss: 4635.8357\n",
      "Epoch 3/3\n",
      "75/75 [==============================] - 135s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0924 - factorized_top_k/top_5_categorical_accuracy: 0.4792 - factorized_top_k/top_10_categorical_accuracy: 0.5529 - factorized_top_k/top_50_categorical_accuracy: 0.6902 - factorized_top_k/top_100_categorical_accuracy: 0.7510 - loss: 4049.7960 - regularization_loss: 0.0000e+00 - total_loss: 4049.7960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f2d5453f70>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TwoTowerModel(query_tower_model=customer_tower_model, candidate_tower_model=article_tower_model)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "\n",
    "model.fit(training_transactions_slices.batch(1024), epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0744c208",
   "metadata": {},
   "source": [
    "#### 2. Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fe73bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 30s 962ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0021 - factorized_top_k/top_5_categorical_accuracy: 0.0066 - factorized_top_k/top_10_categorical_accuracy: 0.0100 - factorized_top_k/top_50_categorical_accuracy: 0.0306 - factorized_top_k/top_100_categorical_accuracy: 0.0505 - loss: 7012.7104 - regularization_loss: 0.0000e+00 - total_loss: 7012.7104\n",
      "{'factorized_top_k/top_1_categorical_accuracy': 0.002095970092341304, 'factorized_top_k/top_5_categorical_accuracy': 0.0066054812632501125, 'factorized_top_k/top_10_categorical_accuracy': 0.010003493167459965, 'factorized_top_k/top_50_categorical_accuracy': 0.030613865703344345, 'factorized_top_k/top_100_categorical_accuracy': 0.05046206712722778, 'loss': 5167.09033203125, 'regularization_loss': 0, 'total_loss': 5167.09033203125}\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(test_transactions_slices.batch(1024), return_dict=True)\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
