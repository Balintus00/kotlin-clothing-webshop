{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fcd11be-9d88-4c0c-9d26-6f7d33dbd311",
   "metadata": {},
   "source": [
    "# Federated learning recommendation system based on the SpFedRec Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78898757-22e0-4ee9-be29-4ce0008b467f",
   "metadata": {},
   "source": [
    "Recommendation systems play a key role in success of modern e-commerce webshop softwares. To create a solution with enchanced data protection, the system's design is based on [federated learning](https://research.ibm.com/blog/what-is-federated-learning). Using federated learning [introduces new challenges](https://arxiv.org/abs/2301.00767) to security, energy and hardware requirements on the client side, system complexity, and communication costs. To tackle these issues, the implementation is based on the [SpFedRec Framework](https://journalofcloudcomputing.springeropen.com/articles/10.1186/s13677-023-00435-5) combined with other well-known techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9763f2-ea04-4b5a-b2da-2e0d3a16c324",
   "metadata": {},
   "source": [
    "TODOS:\n",
    "- concretize this document's main goal\n",
    "- make it clear that this document doesn't distinguish the SAS and REC server from the article but handles it as a single server side component\n",
    "- add explanation that choosing negative items using some kind of strategy is probably a good idea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002bb014-02bf-4798-86bf-2d4046ee9253",
   "metadata": {},
   "source": [
    "## 0. Import dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470dee72-a4e0-4adc-894a-8cbaa842a039",
   "metadata": {},
   "source": [
    "Firstly let's import the dependencies that this notebook requires!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b0136cd-a108-4940-9623-cf7d1336ade3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e55743d-470b-42ac-a90d-2a479a44204f",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7ef32d-1dd8-492d-8258-46f896578c8f",
   "metadata": {},
   "source": [
    "To inspect and try out the implementation, fake data is required. Luckily, a huge and high quality tabular dataset is available for free in this subject area, the [H&M Personalized Fashion Recommendations dataset](https://www.kaggle.com/competitions/h-and-m-personalized-fashion-recommendations). Because of this notebook's goal, I won't use the this whole big dataset, but instead just a little part of it. The following cell contains a small sample from this dataset, and this small sample will be used later to demonstrate the SpFedRec framework. I'm using pandas DataFrame to store the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af9b2cb-d9ad-427b-b8ea-0e95cd6373c8",
   "metadata": {},
   "source": [
    "The sample dataframe contains transactions; one column contains the buyer client's ID and one another column contains the bought item's ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d396e18b-1a10-49d7-b18f-3dc8feb9a986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transactions: 138\n",
      "                                         customer_id  article_id\n",
      "0  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   663713001\n",
      "1  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   541518023\n",
      "2  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   578020002\n",
      "3  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   723529001\n",
      "4  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   351484002\n"
     ]
    }
   ],
   "source": [
    "sample_data = [\n",
    "    [\"000058a12d5b43e67d225668fa1f8d618c13dc232df0cad8ffe7ad4a1091e318\", 663713001],\n",
    "    [\"000058a12d5b43e67d225668fa1f8d618c13dc232df0cad8ffe7ad4a1091e318\", 541518023],\n",
    "    [\"000058a12d5b43e67d225668fa1f8d618c13dc232df0cad8ffe7ad4a1091e318\", 578020002],\n",
    "    [\"000058a12d5b43e67d225668fa1f8d618c13dc232df0cad8ffe7ad4a1091e318\", 723529001],\n",
    "    [\"000058a12d5b43e67d225668fa1f8d618c13dc232df0cad8ffe7ad4a1091e318\", 351484002],\n",
    "    [\"000058a12d5b43e67d225668fa1f8d618c13dc232df0cad8ffe7ad4a1091e318\", 727808001],\n",
    "    [\"000058a12d5b43e67d225668fa1f8d618c13dc232df0cad8ffe7ad4a1091e318\", 727808007],\n",
    "    [\"000058a12d5b43e67d225668fa1f8d618c13dc232df0cad8ffe7ad4a1091e318\", 858883002],\n",
    "    [\"000058a12d5b43e67d225668fa1f8d618c13dc232df0cad8ffe7ad4a1091e318\", 851400006],\n",
    "    [\"000058a12d5b43e67d225668fa1f8d618c13dc232df0cad8ffe7ad4a1091e318\", 750424014],\n",
    "    [\"000058a12d5b43e67d225668fa1f8d618c13dc232df0cad8ffe7ad4a1091e318\", 870304002],\n",
    "    [\"000058a12d5b43e67d225668fa1f8d618c13dc232df0cad8ffe7ad4a1091e318\", 852643001],\n",
    "    [\"000058a12d5b43e67d225668fa1f8d618c13dc232df0cad8ffe7ad4a1091e318\", 852643003],\n",
    "    [\"000058a12d5b43e67d225668fa1f8d618c13dc232df0cad8ffe7ad4a1091e318\", 794321007],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 505221004],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 685687003],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 685687004],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 685687001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 505221001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 508184022],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 522992001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 605106001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 567618001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 528931002],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 349301001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 590414001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 590414002],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 570309005],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 577992001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 552570004],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 649018001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 633150009],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 581162008],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 616808001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 567618002],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 622964004],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 464454004],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 550718001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 583533001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 272591001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 686406001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 413707001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 665851003],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 665851001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 656213001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 351933001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 478549001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 634591002],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 665654001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 724244001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 681569001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 703843001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 609598006],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 682899001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 644073002],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 678079005],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 678079003],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 562637001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 682334001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 609598012],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 629801001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 644763001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 444325004],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 678339001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 628794001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 634591003],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 693387003],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 636392001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 644073001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 664075001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 638939001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 628816002],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 425217006],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 672800001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 703656001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 566618004],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 605939001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 671502001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 694671001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 610665002],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 657291004],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 663613001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 628816005],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 692778001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 655267003],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 692778002],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 660108001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 664368004],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 708352002],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 681376001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 572187001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 752945001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 651697001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 578478001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 745843001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 531526002],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 619580007],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 619580001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 713692001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 779136002],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 708379003],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 719260001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 554784003],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 659983002],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 782643001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 515815001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 619580008],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 784278001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 312878001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 312878010],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 730683001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 787147002],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 614622018],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 745745001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 666444002],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 349301041],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 721257001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 160442010],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 849942001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 372860001],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 160442007],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 304786008],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 554757003],\n",
    "    [\"00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\", 808651003],\n",
    "    [\"000058a12d5b43e67d225668fa1f8d618c13dc232df0cad8ffe7ad4a1091e318\", 663713001],\n",
    "    [\"000058a12d5b43e67d225668fa1f8d618c13dc232df0cad8ffe7ad4a1091e318\", 541518023],\n",
    "    [\"00083cda041544b2fbb0e0d2905ad17da7cf1007526fb4c73235dccbbc132280\", 688873012],\n",
    "    [\"00083cda041544b2fbb0e0d2905ad17da7cf1007526fb4c73235dccbbc132280\", 501323011],\n",
    "    [\"00083cda041544b2fbb0e0d2905ad17da7cf1007526fb4c73235dccbbc132280\", 598859003],\n",
    "    [\"00083cda041544b2fbb0e0d2905ad17da7cf1007526fb4c73235dccbbc132280\", 688873020],\n",
    "    [\"00083cda041544b2fbb0e0d2905ad17da7cf1007526fb4c73235dccbbc132280\", 688873011],\n",
    "    [\"0008968c0d451dbc5a9968da03196fe20051965edde7413775c4eb3be9abe9c2\", 531310002],\n",
    "    [\"0008968c0d451dbc5a9968da03196fe20051965edde7413775c4eb3be9abe9c2\", 529841001],\n",
    "    [\"000aa7f0dc06cd7174389e76c9e132a67860c5f65f970699daccc14425ac31a8\", 501820043],\n",
    "    [\"000aa7f0dc06cd7174389e76c9e132a67860c5f65f970699daccc14425ac31a8\", 501820043],\n",
    "    [\"000aa7f0dc06cd7174389e76c9e132a67860c5f65f970699daccc14425ac31a8\", 674681001],\n",
    "    [\"000aa7f0dc06cd7174389e76c9e132a67860c5f65f970699daccc14425ac31a8\", 671505001],\n",
    "    [\"000aa7f0dc06cd7174389e76c9e132a67860c5f65f970699daccc14425ac31a8\", 671505001],\n",
    "]\n",
    "\n",
    "transactions_df = pd.DataFrame(sample_data, columns =[\"customer_id\", \"article_id\"])\n",
    "\n",
    "transactions_df[\"customer_id\"] = transactions_df[\"customer_id\"].astype(\"string\")\n",
    "transactions_df[\"article_id\"] = pd.to_numeric(transactions_df[\"article_id\"], downcast=\"unsigned\")\n",
    "\n",
    "print(f\"Number of transactions: {len(transactions_df)}\")\n",
    "print(transactions_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a9b529-4f70-45d3-8436-eb0bca6e382f",
   "metadata": {},
   "source": [
    "This notebook demonstrates that particular case, when two clients perform training. Let's choose the IDs of these training clients!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1ed4a9c-abf3-4611-919c-94b52dfdeed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDs of customers that participate in the learning:\n",
      "000058a12d5b43e67d225668fa1f8d618c13dc232df0cad8ffe7ad4a1091e318\n",
      "00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2\n"
     ]
    }
   ],
   "source": [
    "number_of_customer_ids = 2\n",
    "\n",
    "customer_ids = transactions_df[\"customer_id\"].unique()[:number_of_customer_ids]\n",
    "\n",
    "print(\"IDs of customers that participate in the learning:\")\n",
    "for customer_id in customer_ids:\n",
    "    print(customer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd019de-ff69-484f-bcc9-57866901d12c",
   "metadata": {},
   "source": [
    "Let's create dataframes, that contain transactions specifically of the training clients!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "765c001c-5c66-4a8a-a475-a9e5887fce77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataframe_by_customer_id(dataframe, customer_id):\n",
    "    return dataframe[dataframe[\"customer_id\"] == customer_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72f083c4-4dd6-4ad5-8e62-41e4f7d74df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of unique transactions of the 1th client: 14\n",
      "First transactions of the 1. client:\n",
      "                                         customer_id  article_id\n",
      "0  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   663713001\n",
      "1  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   541518023\n",
      "2  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   578020002\n",
      "3  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   723529001\n",
      "4  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   351484002\n",
      "\n",
      "Count of unique transactions of the 2th client: 110\n",
      "First transactions of the 2. client:\n",
      "                                          customer_id  article_id\n",
      "14  00007d2de826758b65a93dd24ce629ed66842531df6699...   505221004\n",
      "15  00007d2de826758b65a93dd24ce629ed66842531df6699...   685687003\n",
      "16  00007d2de826758b65a93dd24ce629ed66842531df6699...   685687004\n",
      "17  00007d2de826758b65a93dd24ce629ed66842531df6699...   685687001\n",
      "18  00007d2de826758b65a93dd24ce629ed66842531df6699...   505221001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "client_transactions_dfs = {}\n",
    "\n",
    "for customer_id in customer_ids:\n",
    "    client_transactions_dfs[customer_id] = filter_dataframe_by_customer_id(transactions_df, customer_id) \\\n",
    "                                            .drop_duplicates()\n",
    "\n",
    "for idx, (client_id, client_transactions_df) in enumerate(client_transactions_dfs.items()):\n",
    "    print(f\"Count of unique transactions of the {idx + 1}th client: {len(client_transactions_df)}\")\n",
    "    print(f\"First transactions of the {idx + 1}. client:\")\n",
    "    print(f\"{client_transactions_df.head()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42779061-ebbf-41d4-bd80-4d376c9486cf",
   "metadata": {},
   "source": [
    "## 2. Traning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b730485-55b9-48bf-8254-e6ad3a642b53",
   "metadata": {},
   "source": [
    "The SpFedRec framework is based on the [Two Tower model](https://cloud.google.com/blog/products/ai-machine-learning/scaling-deep-retrieval-tensorflow-two-towers-architecture). To simply put, this model uses two neural networks to create embedding vectors for query and article items, then nearest neighbour search algorithm is used to find the matching articles to the query. When the model is trained, the neural networks are modified to generate the matching embeddings more similar to each other. The main difference between SpFedRec framework and the basic Two Tower model, that in SpFedRec framework the article tower is stored on a central server, while the query towers are stored on the client side, and each client has their own query tower."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5943456b-1cc3-4959-8068-6a69349ef8cc",
   "metadata": {},
   "source": [
    "To use PyTorch, firstly we need to define that on what kind of hardware we wish to run pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31002df7-d8a6-4d42-a2aa-3a1bcd509e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23df12ce-3308-405f-aca1-b8ee403d9afc",
   "metadata": {},
   "source": [
    "Let's define hyperparameters, on which the model architecture depends on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc44537f-0863-4fd7-bc41-d4b41fabe6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_hidden_linear_layers = 3\n",
    "number_of_neurons_in_layer = 64\n",
    "embedding_vector_dimension = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e977451e-e040-49ba-8118-22f2ceb653fb",
   "metadata": {},
   "source": [
    "Let's define the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93aedd2e-cab2-4f79-beaa-8ac457851880",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TowerModel(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        unique_input_count, \n",
    "        number_of_hidden_linear_layers, \n",
    "        number_of_neurons_in_layer, \n",
    "        output_vector_dimension,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        modules = []\n",
    "        modules.append(\n",
    "            nn.Embedding(\n",
    "                num_embeddings=unique_input_count,\n",
    "                embedding_dim=number_of_neurons_in_layer,\n",
    "            )\n",
    "        )\n",
    "        for hidden_layer_idx in range(0, number_of_hidden_linear_layers):\n",
    "            if hidden_layer_idx != (number_of_hidden_linear_layers - 1):\n",
    "                modules.append(nn.Linear(number_of_neurons_in_layer, number_of_neurons_in_layer))\n",
    "                modules.append(nn.ReLU())\n",
    "            else:\n",
    "                modules.append(nn.Linear(number_of_neurons_in_layer, output_vector_dimension))\n",
    "        self.linear_relu_stack = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear_relu_stack(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970b6392-33ce-4652-844b-9930177571e4",
   "metadata": {},
   "source": [
    "Because an Embedding layer will be used in the tower models, it is required to calculate the count of and items!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a520e24a-2f05-4e3f-80ae-a813145fe576",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique articles: 134\n"
     ]
    }
   ],
   "source": [
    "number_of_unique_article_ids = transactions_df[\"article_id\"].nunique()\n",
    "\n",
    "print(f\"Number of unique articles: {number_of_unique_article_ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03af736f-b86b-4573-bb4e-5c4138524587",
   "metadata": {},
   "source": [
    "After this, it is possible to instantiate the tower models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c2a751b-af56-4f3d-a8c6-ed2cdceb6af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item model:\n",
      "TowerModel(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Embedding(134, 64)\n",
      "    (1): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=64, out_features=16, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Query model for 000058a12d5b43e67d225668fa1f8d618c13dc232df0cad8ffe7ad4a1091e318:\n",
      "TowerModel(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Embedding(2, 64)\n",
      "    (1): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=64, out_features=16, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Query model for 00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2:\n",
      "TowerModel(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Embedding(2, 64)\n",
      "    (1): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=64, out_features=16, bias=True)\n",
      "  )\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "item_model = TowerModel(\n",
    "    unique_input_count=number_of_unique_article_ids,\n",
    "    number_of_hidden_linear_layers=number_of_hidden_linear_layers,\n",
    "    number_of_neurons_in_layer=number_of_neurons_in_layer,\n",
    "    output_vector_dimension=embedding_vector_dimension,\n",
    ").to(device)\n",
    "\n",
    "query_models = {}\n",
    "for customer_id in customer_ids:\n",
    "    query_models[customer_id] = TowerModel(\n",
    "        unique_input_count=number_of_customer_ids,\n",
    "        number_of_hidden_linear_layers=number_of_hidden_linear_layers,\n",
    "        number_of_neurons_in_layer=number_of_neurons_in_layer,\n",
    "        output_vector_dimension=embedding_vector_dimension,\n",
    "    ).to(device)\n",
    "\n",
    "print(f\"Item model:\\n{item_model}\\n\")\n",
    "for customer_id in customer_ids:\n",
    "    print(f\"Query model for {customer_id}:\\n{query_models[customer_id]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cff39b2-9f71-4f18-91ef-ddbc038b868f",
   "metadata": {},
   "source": [
    "Let's define the loss function and the optimizers for the models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf4cd442-2a14-43d3-a34a-2845d77bb93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity_fn = nn.CosineSimilarity()\n",
    "log_softmax_fn = nn.LogSoftmax()\n",
    "nll_loss_fn = nn.NLLLoss()\n",
    "\n",
    "item_model_optimizer = torch.optim.Adam(item_model.parameters())\n",
    "\n",
    "query_model_optimizers = {}\n",
    "for customer_id in customer_ids:\n",
    "    query_model_optimizers[customer_id] = torch.optim.Adam(query_models[customer_id].parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cdfffb-8cde-4527-b261-291b2e45ed41",
   "metadata": {},
   "source": [
    "### 2.1. Client side training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80446a98-efa3-412e-80a4-4facee0a42eb",
   "metadata": {},
   "source": [
    "The first step of the client side training is that the clients request the embeddings of the articles that they previously interacted with (in this sample the interaction means that they bought them). Because this request would leak that with what kind of items the clients interacted with, it would leak private data. So the clients also request embeddings for items, that they didn't interact with previously. Using this technique can be a trade-off for bigger communication overhead, if adding negative items to the training set doesn't really improve the model's behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dc01f7-2d80-4271-82b0-7b9d8b8047de",
   "metadata": {},
   "source": [
    "In this implementation, each client determines the requested negative items' number by fixed rate to the positive items. Let's define this rate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f71ce33-53a2-4c23-86f7-f7ab9c36952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_negative_to_positive_item_per_client_rate = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d2584e-bcb2-492b-9ccc-ae4c1516f5ca",
   "metadata": {},
   "source": [
    "Then let's construct the item queries!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4108d946-e281-4ebf-9e3e-7818a7cee409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_client_item_query(client_transactions_df, transactions_df, customer_id, negative_to_positive_rate):\n",
    "    return pd.concat([\n",
    "        client_transactions_df[\"article_id\"], \n",
    "        transactions_df[transactions_df[\"customer_id\"] != customer_id][\"article_id\"].head(math.ceil(len(client_transactions_df) * negative_to_positive_rate)),\n",
    "    ]).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec708263-7046-4629-aa04-f3f8b96a5d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of queried items of the first client: 18\n",
      "Quried items of the first client:\n",
      "[663713001 541518023 578020002 723529001 351484002 727808001 727808007\n",
      " 858883002 851400006 750424014 870304002 852643001 852643003 794321007\n",
      " 505221004 685687003 685687004 685687001]\n"
     ]
    }
   ],
   "source": [
    "item_queries_of_clients = {}\n",
    "\n",
    "for customer_id in customer_ids:\n",
    "    item_queries_of_clients[customer_id] = create_client_item_query(\n",
    "    client_transactions_df=client_transactions_dfs[customer_id],\n",
    "    transactions_df=transactions_df,\n",
    "    customer_id=customer_id,\n",
    "    negative_to_positive_rate=minimum_negative_to_positive_item_per_client_rate,\n",
    ")\n",
    "\n",
    "print(f\"Number of queried items of the first client: {len(item_queries_of_clients[customer_ids[0]])}\")\n",
    "print(f\"Quried items of the first client:\\n{item_queries_of_clients[customer_ids[0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60429a92-4c57-45c5-b462-9ff9d35b80d1",
   "metadata": {},
   "source": [
    "To train the models labels are needed. Let's label an item with 1 if it's a positive item for the client, 0 otherwise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3c17cf1-ea4e-4530-916f-05b4d3c7dada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(every_item, positive_items):\n",
    "    labels = {}\n",
    "    for item in every_item:\n",
    "        labels[item] = 1 if item in positive_items else 0\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e32d92ff-3940-4a33-ae51-58d362441b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First client's labelled item IDs and values: [(663713001, 1), (541518023, 1), (578020002, 1), (723529001, 1), (351484002, 1), (727808001, 1), (727808007, 1), (858883002, 1), (851400006, 1), (750424014, 1), (870304002, 1), (852643001, 1), (852643003, 1), (794321007, 1), (505221004, 0), (685687003, 0), (685687004, 0), (685687001, 0)]\n"
     ]
    }
   ],
   "source": [
    "labels_of_clients = {}\n",
    "\n",
    "for customer_id in customer_ids:\n",
    "    labels_of_clients[customer_id] = create_labels(\n",
    "        every_item=item_queries_of_clients[customer_id], \n",
    "        positive_items=client_transactions_dfs[customer_id][\"article_id\"].to_numpy(),\n",
    "    )\n",
    "\n",
    "print(f\"First client's labelled item IDs and values: {list(labels_of_clients[customer_ids[0]].items())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ebc6d1-a4d4-42f1-9f6d-d39286803ca6",
   "metadata": {},
   "source": [
    "In this simplified case the model only uses the IDs of the clients and items. The ID fields are a [sparse categorical variables](https://www.kaggle.com/code/colinmorris/embedding-layers), so it's a good idea to use embedding layers to transform these input fields. To pass the IDs to the PyTorch implementation of embedding layer, first we need to encode the IDs into a set of integers of limited size. A simple implementation and solution to this problem, to convert the IDs to their index value of their categorical container set, and then the limit of this set is obviously the size of the categorical container set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec6defa6-85d3-4db0-a3ef-282e14e1b928",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_article_ids = transactions_df[\"article_id\"].unique()\n",
    "\n",
    "def get_index_of_customer_id(customer_id):\n",
    "    return np.where(customer_ids == customer_id)[0][0]\n",
    "\n",
    "def get_index_of_article_id(article_id):\n",
    "    return  np.where(unique_article_ids == article_id)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4b9c6e-5af5-4f1c-93b6-3ec8e1d595e6",
   "metadata": {},
   "source": [
    "In the following step the item embedding vectors are calculated for items, that are contained in any customer item query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e581c941-db52-428a-a0ca-61b418ada846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article ID: 663713001, embedding vector: [ 0.06250614  0.00994737 -0.04070795 -0.00223187 -0.02485958  0.04084307\n",
      "  0.00524519 -0.12380616  0.07251057  0.12679553 -0.09844545 -0.02348811\n",
      "  0.23133865 -0.04011521 -0.09609254 -0.06597807]\n"
     ]
    }
   ],
   "source": [
    "item_embedding_lists = {}\n",
    "\n",
    "for customer_id in customer_ids:\n",
    "    for article_id in item_queries_of_clients[customer_id]:\n",
    "        item_embedding_lists[article_id] = item_model(\n",
    "            torch.from_numpy(np.asarray(get_index_of_article_id(article_id))).to(device).int()\n",
    "        ).detach().numpy()\n",
    "\n",
    "print(f\"Article ID: {list(item_embedding_lists.keys())[0]}, embedding vector: {item_embedding_lists[list(item_embedding_lists.keys())[0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c0a14d-a873-4eff-bfe1-21d0552b4efa",
   "metadata": {},
   "source": [
    "TODO add explanation to DataSet creation and move this to logical place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bbe9e73-a02c-41e7-83ea-08d824b3028a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientTrainingDataset(Dataset):\n",
    "\n",
    "    def __init__(self, item_query_of_client, item_embeddings, labels_of_client):\n",
    "        data = []\n",
    "        labels = []\n",
    "\n",
    "        for item_id in item_query_of_client:\n",
    "            data.append(item_embeddings[item_id])\n",
    "            labels.append(labels_of_client[item_id])\n",
    "        \n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return torch.tensor(self.data[idx]), torch.tensor(self.labels[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8634381-beb7-48b7-ae01-9ee2ad8e4fc4",
   "metadata": {},
   "source": [
    "Now we can define the training loop on the client side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bca940a-7890-41d5-a509-f1f5fb59c31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_tower_train_loop(\n",
    "    client_id,\n",
    "    dataloader,\n",
    "    model,\n",
    "    cosine_similarity_fn, \n",
    "    loss_fn,\n",
    "    log_softmax_fn, \n",
    "    optimizer,\n",
    "):\n",
    "    model.train()\n",
    "    for X, y in dataloader:\n",
    "        query_embedding = model(torch.tensor(get_index_of_customer_id(customer_id)).to(device))\n",
    "        expanded_query_embedding = query_embedding.unsqueeze(0)\n",
    "        query_embedding_in_batch = expanded_query_embedding.repeat(len(X), 1)\n",
    "        similarity = cosine_similarity_fn(X, query_embedding_in_batch)\n",
    "        loss = loss_fn(log_softmax_fn(similarity), y) \n",
    "        loss.backward()\n",
    "        # TODO retrieve gradients\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    print(f\"Loss of client {client_id}: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00898eef-9e22-4e8e-9c52-9c9d42c0b15f",
   "metadata": {},
   "source": [
    "Let's define the batch size hyperparameter of the training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16518ba7-6d9d-4422-b0e1-9cd360fbcdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da05e143-75c5-4c96-b251-4aff9ddaf1bf",
   "metadata": {},
   "source": [
    "After these steps, the training loop can be finally executed for both clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb55a223-7c5f-4668-9d45-fcee908e4a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_client_training_loop():\n",
    "    for customer_id in customer_ids:\n",
    "        query_tower_train_loop(\n",
    "            client_id=customer_id,\n",
    "            dataloader=DataLoader(\n",
    "                dataset=ClientTrainingDataset(\n",
    "                    item_query_of_client=item_queries_of_clients[customer_id],\n",
    "                    item_embeddings=item_embedding_lists,\n",
    "                    labels_of_client=labels_of_clients[customer_id],\n",
    "                ),\n",
    "                batch_size=batch_size,\n",
    "            ),\n",
    "            model=query_models[customer_id],\n",
    "            cosine_similarity_fn=cosine_similarity_fn,\n",
    "            log_softmax_fn=log_softmax_fn,\n",
    "            loss_fn=nll_loss_fn,\n",
    "            optimizer=query_model_optimizers[customer_id],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "036d0434-0547-4118-bd7f-771b9e8514f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of client 000058a12d5b43e67d225668fa1f8d618c13dc232df0cad8ffe7ad4a1091e318: 0.7234421968460083\n",
      "Loss of client 00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2: 0.6931471824645996\n",
      "Loss of client 000058a12d5b43e67d225668fa1f8d618c13dc232df0cad8ffe7ad4a1091e318: 0.6965091228485107\n",
      "Loss of client 00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2: 0.6931471824645996\n",
      "Loss of client 000058a12d5b43e67d225668fa1f8d618c13dc232df0cad8ffe7ad4a1091e318: 0.6720598936080933\n",
      "Loss of client 00007d2de826758b65a93dd24ce629ed66842531df6699338c5570910a014cc2: 0.6931471824645996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n",
      "C:\\Users\\traxler.balint\\AppData\\Local\\Temp\\ipykernel_19356\\2844160162.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss = loss_fn(log_softmax_fn(similarity), y)\n"
     ]
    }
   ],
   "source": [
    "execute_client_training_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfeeeda-b8c7-44f2-936b-742c15601278",
   "metadata": {},
   "source": [
    "### 2.2 Server side training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b61a8e2-a64e-4782-b368-cca759598538",
   "metadata": {},
   "source": [
    "After the client calculated the gradients, they need to upload to the server to update the item model. Because the gradients contain information about the user, the clients can't just simply their gradients. To solve this problem, SpFedRec framework uses circular secret-sharing technique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21eb3f1-0fdc-497c-bd0e-a821f367b221",
   "metadata": {},
   "source": [
    "#### 2.2.1 Central client model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e44b99a-e96f-407d-805b-cf243d59368b",
   "metadata": {},
   "source": [
    "#### 2.2.2 Centrail item model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b841ef2d-3984-493c-a5f2-dacbccc6d36f",
   "metadata": {},
   "source": [
    "## 3. Inferring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348db82d-4ba6-4c9c-ae6f-9eede594b3dc",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a605c931-90cb-421f-99e8-a6976a293c87",
   "metadata": {},
   "source": [
    "## 4. Final thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f9f4e8-f3c0-465c-a4c9-ffc3af3758b4",
   "metadata": {},
   "source": [
    "TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
